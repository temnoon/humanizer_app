#!/usr/bin/env bash
# Humanizer Archive Wrapper (haw) - Comprehensive CLI for all humanizer functionality
# Integrates scripts, APIs, monitoring, and pipeline management

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# Project root detection
find_project_root() {
    local dir="$PWD"
    while [[ "$dir" != "/" ]]; do
        if [[ -f "$dir/humanizer_api/lighthouse/venv/bin/activate" ]]; then
            echo "$dir"
            return 0
        fi
        dir=$(dirname "$dir")
    done
    
    # Fallback to known location
    if [[ -d "/Users/tem/humanizer-lighthouse" ]]; then
        echo "/Users/tem/humanizer-lighthouse"
        return 0
    fi
    
    echo "‚ùå Cannot find humanizer-lighthouse project root" >&2
    return 1
}

# Get project root
PROJECT_ROOT=$(find_project_root)
if [[ $? -ne 0 ]]; then
    exit 1
fi

LIGHTHOUSE_DIR="$PROJECT_ROOT/humanizer_api/lighthouse"
SCRIPTS_DIR="$PROJECT_ROOT/scripts"
HUMANIZER_API_DIR="$PROJECT_ROOT/humanizer_api"
VENV_PATH="$LIGHTHOUSE_DIR/venv/bin/activate"
PYTHON_EXEC="$LIGHTHOUSE_DIR/venv/bin/python"

# Check if venv exists
if [[ ! -f "$VENV_PATH" ]]; then
    echo -e "${RED}‚ùå Virtual environment not found at: $VENV_PATH${NC}" >&2
    echo -e "${YELLOW}üí° Run this to create it:${NC}" >&2
    echo "   cd $LIGHTHOUSE_DIR && python3 -m venv venv && source venv/bin/activate && pip install -r requirements.txt" >&2
    exit 1
fi

# Function to check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to check if port is in use
port_in_use() {
    lsof -i ":$1" >/dev/null 2>&1
}

# Function to check API health
check_api_health() {
    curl -s "http://127.0.0.1:$1/health" >/dev/null 2>&1
}

# Script mapping functions
get_script_name() {
    case "$1" in
        # Writing Analysis
        "extract-writing") echo "personal_writing_extractor.py" ;;
        "browse-writing") echo "writing_style_browser.py" ;;
        "browse-wordclouds") echo "word_cloud_browser.py" ;;
        "browse-notebooks") echo "notebook_transcript_browser.py" ;;
        "curate-book") echo "notebook_book_curator.py" ;;
        "explore-themes") echo "thematic_cluster_explorer.py" ;;
        "book-factory") echo "automated_book_factory.py" ;;
        "book-editor") echo "ai_book_editor.py" ;;
        "book-pipeline") echo "complete_book_pipeline.py" ;;
        "advanced-books") echo "advanced_book_factory.py" ;;
        "universal-books") echo "universal_book_generator.py" ;;
        "book-create") echo "enhanced_book_creator.py" ;;
        "joplin-export") echo "joplin_export_generator_fixed_v2.py" ;;
        
        # Embedding & Search
        "embed") echo "hierarchical_embedder.py" ;;
        "embed-full") echo "full_archive_embedder.py" ;;
        "monitor") echo "embedding_monitor.py" ;;
        
        # Content Analysis
        "assess") echo "batch_conversation_assessor.py" ;;
        "sample") echo "conversation_sampler.py" ;;
        "wordcloud") echo "conversation_word_cloud.py" ;;
        "categorize") echo "content_categorizer.py" ;;
        
        # Archive CLI Integration
        "archive") echo "$LIGHTHOUSE_DIR/archive_cli.py" ;;
        "embedding-cli") echo "$LIGHTHOUSE_DIR/embedding_cli.py" ;;
        "allegory") echo "$LIGHTHOUSE_DIR/allegory_cli.py" ;;
        "humanizer") echo "$LIGHTHOUSE_DIR/humanizer_cli.py" ;;
        "integrated") echo "$LIGHTHOUSE_DIR/integrated_processing_cli.py" ;;
        "attribute") echo "$LIGHTHOUSE_DIR/attribute_browser_cli.py" ;;
        
        # New Metadata & Pipeline Tools
        "browse") echo "metadata_browser.py" ;;
        "browse-chunks") echo "semantic_chunks_browser.py" ;;
        "agentic") echo "agentic_assessment.py" ;;
        "pipeline") echo "content_pipeline.py" ;;
        "pipeline-mgr") echo "pipeline_manager.py" ;;
        
        *) echo "" ;;
    esac
}

get_api_script() {
    case "$1" in
        "archive-api") echo "$HUMANIZER_API_DIR/src/archive_api.py" ;;
        "lpe-api") echo "$HUMANIZER_API_DIR/src/lpe_api.py" ;;
        "simple-archive") echo "$HUMANIZER_API_DIR/src/simple_archive_api.py" ;;
        "lawyer-api") echo "$HUMANIZER_API_DIR/src/lawyer_api_main.py" ;;
        "lighthouse-api") echo "$LIGHTHOUSE_DIR/api_enhanced.py" ;;
        "pipeline-api") echo "$LIGHTHOUSE_DIR/pipeline_api.py" ;;
        "lighthouse-ui") echo "lighthouse-ui" ;;  # Special case for frontend
        *) echo "" ;;
    esac
}

# System status check
check_system_status() {
    echo -e "${CYAN}üîç System Status Check${NC}"
    echo "=" * 50
    
    # Python environment
    if [[ -f "$PYTHON_EXEC" ]]; then
        echo -e "${GREEN}‚úÖ Python environment ready${NC}"
        PYTHON_VERSION=$($PYTHON_EXEC --version)
        echo -e "   $PYTHON_VERSION"
    else
        echo -e "${RED}‚ùå Python environment not found${NC}"
    fi
    
    # PostgreSQL
    if command_exists pg_isready; then
        if pg_isready >/dev/null 2>&1; then
            echo -e "${GREEN}‚úÖ PostgreSQL running${NC}"
        else
            echo -e "${YELLOW}‚ö†Ô∏è  PostgreSQL not running${NC}"
        fi
    else
        echo -e "${YELLOW}‚ö†Ô∏è  PostgreSQL not installed${NC}"
    fi
    
    # Ollama
    if command_exists ollama; then
        if curl -s http://localhost:11434/api/tags >/dev/null 2>&1; then
            echo -e "${GREEN}‚úÖ Ollama running${NC}"
        else
            echo -e "${YELLOW}‚ö†Ô∏è  Ollama not running${NC}"
        fi
    else
        echo -e "${YELLOW}‚ö†Ô∏è  Ollama not installed${NC}"
    fi
    
    # APIs
    echo -e "${BLUE}üåê API Services:${NC}"
    local apis=(
        "8100:Enhanced Lighthouse API"
        "7200:Archive API"
        "7201:LPE API"
        "7202:Lawyer API"
        "7204:Pipeline API"
        "3100:Lighthouse UI"
    )
    
    for api in "${apis[@]}"; do
        local port="${api%%:*}"
        local name="${api##*:}"
        if port_in_use "$port"; then
            if check_api_health "$port" 2>/dev/null; then
                echo -e "${GREEN}‚úÖ $name (port $port)${NC}"
            else
                echo -e "${YELLOW}‚ö†Ô∏è  $name (port $port) - responding but no health endpoint${NC}"
            fi
        else
            echo -e "${RED}‚ùå $name (port $port)${NC}"
        fi
    done
}

# Show active processes
show_processes() {
    echo -e "${CYAN}üîç Active Humanizer Processes${NC}"
    echo "=================================================="
    
    # Scripts to monitor
    local scripts=(
        'api_enhanced.py' 'archive_api.py' 'lpe_api.py' 'lawyer_api_main.py'
        'hierarchical_embedder.py' 'full_archive_embedder.py' 'embedding_monitor.py'
        'personal_writing_extractor.py' 'batch_conversation_assessor.py'
        'archive_cli.py' 'embedding_cli.py' 'allegory_cli.py'
        'metadata_browser.py' 'agentic_assessment.py' 'content_pipeline.py'
        'conversation_word_cloud.py' 'semantic_chunks_browser.py'
    )
    
    local found_processes=false
    
    for script in "${scripts[@]}"; do
        # Use pgrep to find processes running this script
        local pids=$(pgrep -f "$script" 2>/dev/null || true)
        
        if [[ -n "$pids" ]]; then
            found_processes=true
            for pid in $pids; do
                if ps -p "$pid" > /dev/null 2>&1; then
                    echo -e "  üü¢ PID $pid: $script"
                    
                    # Get memory usage (RSS in KB, convert to MB)
                    local mem_kb=$(ps -o rss= -p "$pid" 2>/dev/null || echo "0")
                    local mem_mb=$((mem_kb / 1024))
                    
                    # Get command line for parameters
                    local cmdline=$(ps -o args= -p "$pid" 2>/dev/null || echo "")
                    
                    echo "      Memory: ${mem_mb}MB"
                    
                    # Extract key parameters
                    if [[ "$cmdline" =~ --limit[[:space:]]+([0-9]+) ]]; then
                        echo "      --limit: ${BASH_REMATCH[1]}"
                    fi
                    if [[ "$cmdline" =~ --batch-size[[:space:]]+([0-9]+) ]]; then
                        echo "      --batch-size: ${BASH_REMATCH[1]}"
                    fi
                    if [[ "$cmdline" =~ --timeout[[:space:]]+([0-9]+) ]]; then
                        echo "      --timeout: ${BASH_REMATCH[1]}"
                    fi
                    echo
                fi
            done
        fi
    done
    
    # Also check for common port usage
    echo -e "${YELLOW}üì° Active API Ports:${NC}"
    local ports=(7200 7201 7202 8100 3100 3101)
    local found_ports=false
    
    for port in "${ports[@]}"; do
        local port_info=$(lsof -ti:$port 2>/dev/null || true)
        if [[ -n "$port_info" ]]; then
            found_ports=true
            local service_name=""
            case $port in
                7200) service_name="Archive API" ;;
                7201) service_name="LPE API" ;;
                7202) service_name="Lawyer API" ;;
                8100) service_name="Lighthouse API" ;;
                3100|3101) service_name="Lighthouse UI" ;;
            esac
            echo "  üåê Port $port: $service_name (PID: $port_info)"
        fi
    done
    
    if [[ "$found_processes" == false ]] && [[ "$found_ports" == false ]]; then
        echo "  ‚ö™ No active humanizer processes or services found"
    fi
}

# Show recent logs
show_logs() {
    echo -e "${CYAN}üìù Recent Log Activity${NC}"
    echo "=" * 50
    
    local log_dirs=(
        "$LIGHTHOUSE_DIR/logs"
        "$HUMANIZER_API_DIR/logs" 
        "$SCRIPTS_DIR/logs"
    )
    
    local log_patterns=(
        "*.log"
        "api*.log"
        "embedding*.log"
        "batch*.log"
    )
    
    local found_logs=false
    for log_dir in "${log_dirs[@]}"; do
        if [[ -d "$log_dir" ]]; then
            for pattern in "${log_patterns[@]}"; do
                for log_file in "$log_dir"/$pattern; do
                    if [[ -f "$log_file" ]]; then
                        found_logs=true
                        echo -e "${BLUE}--- ${log_file##*/} ---${NC}"
                        tail -n 3 "$log_file" 2>/dev/null | sed 's/^/  /'
                        echo
                    fi
                done
            done
        fi
    done
    
    if [[ "$found_logs" == false ]]; then
        echo "  ‚ö™ No recent log files found"
    fi
}

# API management functions
start_api() {
    local api_name="$1"
    local script_path=$(get_api_script "$api_name")
    
    if [[ -z "$script_path" ]]; then
        echo -e "${RED}‚ùå Unknown API: $api_name${NC}"
        return 1
    fi
    
    # Special handling for lighthouse-ui
    if [[ "$api_name" == "lighthouse-ui" ]]; then
        echo -e "${GREEN}üöÄ Starting Lighthouse UI...${NC}"
        cd "$PROJECT_ROOT/lighthouse-ui"
        
        # Kill any existing process on port 3100
        lsof -ti:3100 | xargs kill -9 2>/dev/null || true
        sleep 1
        
        # Start frontend with correct port
        nohup bash -c "VITE_PORT=3100 npm run dev" > "$LIGHTHOUSE_DIR/logs/lighthouse-ui.log" 2>&1 &
        local pid=$!
        echo -e "${GREEN}‚úÖ Started Lighthouse UI (PID: $pid)${NC}"
        echo "   URL: http://127.0.0.1:3100"
        echo "   Logs: $LIGHTHOUSE_DIR/logs/lighthouse-ui.log"
        return 0
    fi
    
    if [[ ! -f "$script_path" ]]; then
        echo -e "${RED}‚ùå API script not found: $script_path${NC}"
        return 1
    fi
    
    echo -e "${GREEN}üöÄ Starting $api_name...${NC}"
    cd "$LIGHTHOUSE_DIR"
    source "$VENV_PATH"
    
    # Start in background with logging
    nohup $PYTHON_EXEC "$script_path" > "logs/${api_name}.log" 2>&1 &
    local pid=$!
    echo -e "${GREEN}‚úÖ Started $api_name (PID: $pid)${NC}"
    echo "   Logs: logs/${api_name}.log"
}

stop_api() {
    local api_name="$1"
    local script_path=$(get_api_script "$api_name")
    
    if [[ -z "$script_path" ]]; then
        echo -e "${RED}‚ùå Unknown API: $api_name${NC}"
        return 1
    fi
    
    echo -e "${YELLOW}üõë Stopping $api_name...${NC}"
    
    # Special handling for lighthouse-ui
    if [[ "$api_name" == "lighthouse-ui" ]]; then
        # Kill processes on port 3100
        local pids=$(lsof -ti:3100 2>/dev/null || true)
        if [[ -n "$pids" ]]; then
            echo "$pids" | xargs kill -TERM 2>/dev/null || true
            sleep 2
            echo "$pids" | xargs kill -KILL 2>/dev/null || true
            echo -e "${GREEN}‚úÖ Stopped Lighthouse UI${NC}"
        else
            echo -e "${YELLOW}‚ö†Ô∏è  Lighthouse UI was not running${NC}"
        fi
        return 0
    fi
    
    # Find and kill processes running this script
    local pids=$(pgrep -f "$(basename "$script_path")") || true
    if [[ -n "$pids" ]]; then
        echo "$pids" | xargs kill -TERM 2>/dev/null || true
        sleep 2
        # Force kill if still running
        echo "$pids" | xargs kill -KILL 2>/dev/null || true
        echo -e "${GREEN}‚úÖ Stopped $api_name${NC}"
    else
        echo -e "${YELLOW}‚ö†Ô∏è  $api_name was not running${NC}"
    fi
}

# Show comprehensive help
show_help() {
    echo -e "${PURPLE}ü§ñ Humanizer Archive Wrapper (haw) - Comprehensive CLI${NC}"
    echo "================================================================"
    echo "Usage: haw <command> [arguments...]"
    echo ""
    
    echo -e "${GREEN}üìä System Management:${NC}"
    echo "  status               System status and health checks"
    echo "  processes            Show active humanizer processes"  
    echo "  logs                 View recent log activity"
    echo "  setup                Setup/repair Python environment"
    echo ""
    
    echo -e "${GREEN}üìù Writing Analysis:${NC}"
    echo "  extract-writing      Extract and analyze personal writing style"
    echo "    extract [--limit N] [--min-length N] [--max-length N]"
    echo "  browse-writing       Browse and explore writing style analysis results"
    echo "    browse | summary | details | samples [filter]"
    echo "  browse-wordclouds    Explore searchable word clouds and frequency patterns"
    echo "    browse | search <word> | topic <words> | title <query> | trending"
    echo "  browse-notebooks     Discover and analyze handwritten notebook transcripts"
    echo "    browse | list | analyze <conv_id> | export <conv_id>"
    echo "  curate-book          Agent-assisted book curation from notebook insights"
    echo "    curate | analyze"
    echo "  explore-themes       Demonstrate thematic clustering capabilities"
    echo "  book-factory         Automated generation of 7 books from insights"
    echo "    --dry-run | --quality-threshold 0.3"
    echo "  book-editor          AI-assisted editorial refinement of generated books"
    echo "    --book <filename> | process all books"
    echo "  book-pipeline        Complete automated book production workflow"
    echo "    --dry-run | --quality-threshold 0.3"
    echo "  advanced-books       Sophisticated semantic clustering and book generation"
    echo "    --min-quality 0.4 --max-books 5 --analyze-only"
    echo "  universal-books      General-purpose book generator for any content source"
    echo "    --source-type notebooks|conversations|files --min-quality 0.4"
    echo "  book-create          Interactive book creator with multiple selection methods"
    echo "    interactive | --mode advanced | --mode export --book-file <file>"
    echo "  joplin-export        Export book to Joplin-importable format (.jex)"
    echo "    <book-file> [--output-dir <dir>] [--title <title>]"
    echo ""
    
    echo -e "${GREEN}üß† Embedding & Search:${NC}"
    echo "  embed                Hierarchical embedding (test batches)"
    echo "    embed [--limit N] [--timeout N]"
    echo "  embed-full           Full archive embedding"
    echo "    --batch-size N --timeout N --min-score N"
    echo "  monitor              Monitor embedding progress"
    echo "    dashboard | status | stats"
    echo ""
    
    echo -e "${GREEN}üìä Content Analysis:${NC}"
    echo "  assess               Batch conversation quality assessment" 
    echo "  sample               Extract representative conversation samples"
    echo "  wordcloud            Generate archive word clouds"
    echo "  categorize           Content categorization"
    echo ""
    
    echo -e "${GREEN}üìÅ Archive Management:${NC}"
    echo "  archive              Launch archive CLI"
    echo "    list | search <query> | get <id> | stats"
    echo "  embedding-cli        Embedding corpus management"
    echo "  allegory             Allegory engine CLI"
    echo "  humanizer            Main humanizer CLI"
    echo "  integrated           Integrated processing CLI"
    echo "  attribute            Attribute browser CLI"
    echo ""
    
    echo -e "${GREEN}üîç Metadata & Intelligence:${NC}"
    echo "  browse               Interactive metadata browser"
    echo "    browse | overview | search [filters] | export"
    echo "  browse-chunks        Explore semantic chunks and summaries"
    echo "    browse | list | explore <conv_id> | search <term>"
    echo "  agentic              Intelligent content assessment"
    echo "    assess <task_type> | results [filters]"
    echo "  pipeline             Content transformation pipeline"
    echo "    process [filters] | status | config"
    echo "  pipeline-mgr         Formal pipeline API management"
    echo "    rules list | execute --min-quality 0.8 | stats"
    echo ""
    
    echo -e "${GREEN}üåê API Services:${NC}"
    echo "  api start <service>  Start API service"
    echo "  api stop <service>   Stop API service"
    echo "  api restart <service> Restart API service"
    echo "  api list             List available API services"
    echo "  start-lighthouse     Start both API and UI together"
    echo "  stop-lighthouse      Stop both API and UI together"
    echo ""
    echo "    Services: lighthouse-api, lighthouse-ui, archive-api, lpe-api, lawyer-api, pipeline-api, simple-archive"
    echo ""
    
    echo -e "${GREEN}üîÑ Pipeline Management:${NC}"
    echo "  pipeline run <name>  Run predefined pipeline"
    echo "  pipeline list        List available pipelines"
    echo "  pipeline status      Show pipeline status"
    echo ""
    echo "    Pipelines: full-analysis, writing-profile, content-audit, embedding-refresh"
    echo ""
    
    echo -e "${YELLOW}Examples:${NC}"
    echo "  haw status                           # System health check"
    echo "  haw start-lighthouse                 # Start both API and UI"
    echo "  haw extract-writing extract --limit 1000"
    echo "  haw embed-full --batch-size 50 --timeout 120"
    echo "  haw api start lighthouse-api"
    echo "  haw archive search \"consciousness\""
    echo "  haw pipeline run full-analysis"
    echo ""
    echo "  # Metadata exploration and intelligence"
    echo "  haw browse browse                    # Interactive metadata browser"
    echo "  haw agentic assess gem_detection     # Find exceptional insights" 
    echo "  haw pipeline process --min-quality 0.8  # Transform high-quality content"
    echo "  haw pipeline-mgr execute --min-quality 0.8 --dry-run  # Preview pipeline execution"
    echo ""
    
    echo -e "${BLUE}Environment:${NC}"
    echo "  Project Root: $PROJECT_ROOT"
    echo "  Python Env:   $VENV_PATH"
    echo "  Scripts Dir:  $SCRIPTS_DIR"
    echo "  APIs Dir:     $HUMANIZER_API_DIR"
    echo ""
}

# Pipeline management
run_pipeline() {
    local pipeline="$1"
    shift
    
    case "$pipeline" in
        "full-analysis")
            echo -e "${CYAN}üîÑ Running Full Archive Analysis Pipeline${NC}"
            echo "This will run: assess -> categorize -> wordcloud -> embed-full"
            read -p "Continue? (y/N): " -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                haw assess --limit 1000
                haw categorize --limit 1000  
                haw wordcloud --conversations 1000
                haw embed-full --batch-size 50
            fi
            ;;
            
        "writing-profile")
            echo -e "${CYAN}üîÑ Running Personal Writing Profile Pipeline${NC}"
            echo "This will extract and analyze your writing style comprehensively"
            read -p "Continue? (y/N): " -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                haw extract-writing extract --limit 2000
                echo -e "${GREEN}‚úÖ Writing profile complete!${NC}"
            fi
            ;;
            
        "content-audit")
            echo -e "${CYAN}üîÑ Running Content Quality Audit Pipeline${NC}"
            echo "This will assess quality, extract samples, and categorize content"
            read -p "Continue? (y/N): " -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                haw assess
                haw sample --limit 50
                haw categorize
            fi
            ;;
            
        "embedding-refresh")
            echo -e "${CYAN}üîÑ Running Embedding Corpus Refresh${NC}"
            echo "This will rebuild the entire embedding corpus"
            read -p "This is a long operation. Continue? (y/N): " -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                haw embed-full --batch-size 25 --timeout 180
            fi
            ;;
            
        "gem-discovery")
            echo -e "${CYAN}üîÑ Running Gem Discovery Pipeline${NC}"
            echo "This will identify exceptional insights and transform them for publication"
            read -p "Continue? (y/N): " -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                haw agentic assess gem_detection --min-quality 0.6
                haw pipeline process --min-quality 0.8
            fi
            ;;
            
        "content-transformation")
            echo -e "${CYAN}üîÑ Running Content Transformation Pipeline${NC}"
            echo "This will transform quality content into multiple publication formats"
            read -p "Continue? (y/N): " -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                haw agentic assess editorial_assessment --min-quality 0.5
                haw pipeline process --category philosophical --min-quality 0.6
                haw pipeline process --category technical --min-quality 0.6
            fi
            ;;
            
        "intelligence-gathering")
            echo -e "${CYAN}üîÑ Running Intelligence Gathering Pipeline${NC}"
            echo "This will analyze patterns and assess content for strategic insights"
            read -p "Continue? (y/N): " -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                haw browse overview
                haw agentic assess cross_conversation_patterns --limit 50
                haw agentic assess topic_depth_analysis --min-quality 0.7
            fi
            ;;
            
        *)
            echo -e "${RED}‚ùå Unknown pipeline: $pipeline${NC}"
            echo -e "${YELLOW}Available pipelines: full-analysis, writing-profile, content-audit, embedding-refresh, 
                     gem-discovery, content-transformation, intelligence-gathering${NC}"
            return 1
            ;;
    esac
}

# Main command dispatcher
main() {
    if [[ $# -eq 0 ]] || [[ "$1" == "help" ]] || [[ "$1" == "--help" ]] || [[ "$1" == "-h" ]]; then
        show_help
        exit 0
    fi
    
    COMMAND="$1"
    shift
    
    case "$COMMAND" in
        # System Management
        "status")
            check_system_status
            ;;
            
        "processes"|"ps")
            show_processes
            ;;
            
        "logs")
            show_logs
            ;;
            
        "setup"|"install")
            echo -e "${YELLOW}üîß Setting up Python environment...${NC}"
            cd "$LIGHTHOUSE_DIR"
            rm -rf venv
            python3 -m venv venv
            source venv/bin/activate
            pip install --upgrade pip
            pip install -r requirements.txt
            echo -e "${GREEN}‚úÖ Setup completed${NC}"
            ;;
            
        # API Management
        "api")
            if [[ $# -eq 0 ]]; then
                echo -e "${YELLOW}Available API commands: start, stop, restart, list${NC}"
                exit 1
            fi
            
            api_command="$1"
            shift
            
            case "$api_command" in
                "start")
                    if [[ $# -eq 0 ]]; then
                        echo -e "${YELLOW}Usage: haw api start <service>${NC}"
                        exit 1
                    fi
                    start_api "$1"
                    ;;
                "stop")
                    if [[ $# -eq 0 ]]; then
                        echo -e "${YELLOW}Usage: haw api stop <service>${NC}"
                        exit 1
                    fi
                    stop_api "$1"
                    ;;
                "restart")
                    if [[ $# -eq 0 ]]; then
                        echo -e "${YELLOW}Usage: haw api restart <service>${NC}"
                        exit 1
                    fi
                    stop_api "$1"
                    sleep 2
                    start_api "$1"
                    ;;
                "list")
                    echo -e "${CYAN}Available API Services:${NC}"
                    echo "  lighthouse-api    Enhanced Lighthouse API (port 8100)"
                    echo "  lighthouse-ui     Lighthouse Frontend UI (port 3100)"
                    echo "  archive-api       Archive management API (port 7200)"
                    echo "  lpe-api          Lamish Projection Engine API (port 7201)"
                    echo "  lawyer-api       Content quality assessment API (port 7202)"
                    echo "  pipeline-api     Content Pipeline API (port 7204)"
                    echo "  simple-archive   Simple archive API (minimal dependencies)"
                    ;;
                *)
                    echo -e "${RED}‚ùå Unknown API command: $api_command${NC}"
                    exit 1
                    ;;
            esac
            ;;
            
        # Pipeline Management
        "pipeline")
            if [[ $# -eq 0 ]]; then
                echo -e "${YELLOW}Available pipeline commands: run, list, status${NC}"
                exit 1
            fi
            
            pipeline_command="$1"
            shift
            
            case "$pipeline_command" in
                "run")
                    if [[ $# -eq 0 ]]; then
                        echo -e "${YELLOW}Usage: haw pipeline run <pipeline-name>${NC}"
                        exit 1
                    fi
                    run_pipeline "$@"
                    ;;
                "list")
                    echo -e "${CYAN}Available Pipelines:${NC}"
                    echo ""
                    echo -e "${GREEN}üìä Analysis Pipelines:${NC}"
                    echo "  full-analysis        Complete archive analysis (assess + categorize + wordcloud + embed)"
                    echo "  content-audit        Quality assessment and sampling"
                    echo "  intelligence-gathering Pattern analysis and strategic insights"
                    echo ""
                    echo -e "${GREEN}üìù Content Pipelines:${NC}"
                    echo "  writing-profile      Personal writing style extraction and analysis"
                    echo "  gem-discovery        Identify exceptional insights for publication"
                    echo "  content-transformation Transform quality content to multiple formats"
                    echo ""
                    echo -e "${GREEN}üß† Technical Pipelines:${NC}"
                    echo "  embedding-refresh    Complete embedding corpus rebuild"
                    ;;
                "status")
                    echo -e "${CYAN}Pipeline Status:${NC}"
                    show_processes | grep -E "(embed|assess|categorize|extract)" || echo "  ‚ö™ No pipelines currently running"
                    ;;
                *)
                    echo -e "${RED}‚ùå Unknown pipeline command: $pipeline_command${NC}"
                    exit 1
                    ;;
            esac
            ;;
            
        # Lighthouse convenience commands
        "start-lighthouse")
            echo -e "${CYAN}üöÄ Starting Complete Lighthouse System${NC}"
            echo "This will start both the Enhanced Lighthouse API and Frontend UI"
            echo ""
            start_api "lighthouse-api"
            sleep 3
            start_api "lighthouse-ui"
            echo ""
            echo -e "${GREEN}‚úÖ Lighthouse system started!${NC}"
            echo -e "${YELLOW}üåê Frontend: http://127.0.0.1:3100${NC}"
            echo -e "${YELLOW}üåê API: http://127.0.0.1:8100${NC}"
            ;;
            
        "stop-lighthouse")
            echo -e "${YELLOW}üõë Stopping Complete Lighthouse System${NC}"
            stop_api "lighthouse-ui"
            stop_api "lighthouse-api"
            echo -e "${GREEN}‚úÖ Lighthouse system stopped${NC}"
            ;;
            
        # Script-based commands (existing functionality)
        *)
            # Check if it's a script command
            SCRIPT_NAME=$(get_script_name "$COMMAND")
            
            if [[ -n "$SCRIPT_NAME" ]]; then
                # Handle scripts in SCRIPTS_DIR vs LIGHTHOUSE_DIR
                if [[ "$SCRIPT_NAME" == "$LIGHTHOUSE_DIR"* ]]; then
                    SCRIPT_PATH="$SCRIPT_NAME"
                else
                    SCRIPT_PATH="$SCRIPTS_DIR/$SCRIPT_NAME"
                fi
                
                # Check if script exists
                if [[ ! -f "$SCRIPT_PATH" ]]; then
                    echo -e "${RED}‚ùå Script not found: $SCRIPT_PATH${NC}" >&2
                    exit 1
                fi
                
                # Show what we're doing
                echo -e "${BLUE}üöÄ Running: $COMMAND${NC}"
                echo -e "${GREEN}üìç Project: $PROJECT_ROOT${NC}"
                echo -e "${GREEN}üêç Script:  $SCRIPT_PATH${NC}"
                echo -e "${GREEN}üìÇ Working: $LIGHTHOUSE_DIR${NC}"
                echo ""
                
                # Change to lighthouse directory and run with venv
                cd "$LIGHTHOUSE_DIR"
                
                # Source the virtual environment and run the script
                exec bash -c "
                    source '$VENV_PATH' || {
                        echo -e '${RED}‚ùå Failed to activate virtual environment${NC}' >&2
                        exit 1
                    }
                    
                    # Run the script
                    python '$SCRIPT_PATH' \"\$@\"
                " -- "$@"
                
            else
                echo -e "${RED}‚ùå Unknown command: $COMMAND${NC}" >&2
                echo -e "${YELLOW}üí° Run 'haw help' to see available commands${NC}" >&2
                exit 1
            fi
            ;;
    esac
}

# Run main function with all arguments
main "$@"